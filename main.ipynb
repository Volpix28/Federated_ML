{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter notebook magic to reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import load_model, save_model, set_model_weights, visualize_federated_learning_performance\n",
    "from data_utils import load_client_data, load_dataset, load_dataloader\n",
    "from federated_utils import federated_averaging, train_on_clients\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./dataset/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:02<00:00, 10753820.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./dataset/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./dataset/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 1005685.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./dataset/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./dataset/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4422102/4422102 [00:00<00:00, 8044869.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./dataset/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./dataset/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 7733623.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./dataset/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, val_dataloader = load_dataset(classes=[\n",
    "    0, # T-shirt/top\n",
    "    1, # Trouser\n",
    "    3, # Dress\n",
    "], samples_per_class=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3000 training examples\n"
     ]
    }
   ],
   "source": [
    "samples_count = sum([len(data) for data, _ in train_dataloader])\n",
    "print(f\"Loaded {samples_count} training examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_federated_learning_experiment(num_clients, num_rounds, local_epochs, model_path, save_path_prefix, ml_aggregation_method):\n",
    "    samples_per_node = samples_count // num_clients\n",
    "    \n",
    "    # Load initial model\n",
    "    global_model = load_model(model_path)\n",
    "    global_train_dataset, global_val_dataset = load_dataset(classes=[\n",
    "        0, # T-shirt/top\n",
    "        1, # Trouser\n",
    "        3, # Dress\n",
    "    ], samples_per_class=1000)\n",
    "\n",
    "    # Load client models and data\n",
    "    client_models = [copy.deepcopy(global_model) for _ in range(num_clients)]\n",
    "    client_data = [load_dataloader(global_train_dataset, global_val_dataset, client_id=i, num_samples=samples_per_node) for i in range(num_clients)]\n",
    "\n",
    "    for round_num in range(num_rounds):\n",
    "        print(f\"Round {round_num + 1}/{num_rounds}\")\n",
    "        train_on_clients(client_models, client_data, local_epochs)\n",
    "\n",
    "        if ml_aggregation_method == \"fedavg\":\n",
    "            averaged_weights = federated_averaging(client_models)\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Aggregation method {ml_aggregation_method} not implemented\")\n",
    "\n",
    "        set_model_weights(global_model, averaged_weights)\n",
    "\n",
    "        # evaluate - what KPI´s do we want?\n",
    "\n",
    "        for client_model in client_models:\n",
    "            set_model_weights(client_model, averaged_weights)\n",
    "\n",
    "    # Save the final model\n",
    "    save_path = f\"{save_path_prefix}_clients{num_clients}_rounds{num_rounds}_epochs{local_epochs}.h5\"\n",
    "    save_model(global_model, save_path)\n",
    "    print(f\"Saved model to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_range = range(2, 11)  # 2 to 10 nodes\n",
    "local_epoch_range = range(1, 11)  # 1 to 10 local epochs\n",
    "global_epoch_range = range(1, 6)  # 1 to 5 global epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_folder = \"./models\"\n",
    "model_filename = \"your_model_file\"\n",
    "model_path = os.path.join(model_folder, model_filename)\n",
    "save_path_prefix = \"./saved_models/model\"\n",
    "\n",
    "# Ensure the save directory exists\n",
    "os.makedirs(os.path.dirname(save_path_prefix), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
